# Distributed LLM Inference System

## Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Validate Setup
```bash
python setup_validator.py --validate-all
```

### 3. Start Server
```bash
python start_server.py --node-id physical_node_1 --config network_config.json
```

### 4. Start Chatbot Client
```bash
python chatbot_interface.py --tokenizer-path assets/models/llama3_1_8b_fp16/blocks/tokenizer
```

## Project Structure
- `model_node.py` - Main inference server
- `config_manager.py` - Configuration management
- `worker_lib.py` - CPU/GPU workers
- `chatbot_interface.py` - Chat client
- `assets/models/` - Model files
- `logs/` - Log files
- `sessions/` - Session data

## Configuration
- Network config: `network_config.json`
- Model metadata: `assets/models/llama3_1_8b_fp16/metadata.json`
- Portable config: `portable_config.json`

## Troubleshooting
1. Run validator: `python setup_validator.py --validate-all --fix`
2. Check logs in `logs/` directory
3. Verify model files in `assets/models/`

Generated by setup_validator.py on D:\Tiktrue\Tiktrue_Platform

## ğŸ“Š Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø³ÛŒØ³ØªÙ… (System Profiling)

### Ú†Ø±Ø§ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø³ÛŒØ³ØªÙ… Ù…Ù‡Ù… Ø§Ø³ØªØŸ

Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø³ÛŒØ³ØªÙ… **Ø¶Ø±ÙˆØ±ÛŒ** Ø§Ø³Øª Ú†ÙˆÙ†:
- ğŸ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒØ³ØªÙ… Ø´Ù…Ø§ Ø±Ùˆ Ø±ÙˆÛŒ Ù‡Ø± Ù…Ø¯Ù„ ØªØ³Øª Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- ğŸ“„ ÙØ§ÛŒÙ„ `performance_profile.json` Ø±Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- ğŸ§  Scheduler Ø§Ø² Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ÛŒÙ†Ù‡ CPU/GPU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- âš¡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø±Ùˆ Ù…ÛŒâ€ŒØ³Ø§Ø²Ù‡

### Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡:

```bash
# Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ… (ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
python start_server.py --profile-system

# Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¨Ø§ Ù…Ø¯Ù„ Ø®Ø§Øµ
python start_server.py --profile-system --model llama3_1_8b_fp16

# Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ù…Ø³ØªÙ‚Ù„
python static_profiler.py --network-config network_config.json

# ÙÙ‚Ø· Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
python static_profiler.py --network-config network_config.json --optimize-only

# ÙÙ‚Ø· ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯
python static_profiler.py --network-config network_config.json --profile-only
```

### Ø®Ø±ÙˆØ¬ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„:

```
ğŸ“Š PROFILING SUMMARY
============================================================

ğŸ”¹ BLOCK_1:
   CPU                 :   45.2ms
   Dml                 :   23.1ms

ğŸ”¹ BLOCK_2:
   CPU                 :   42.8ms
   Dml                 :   25.3ms

...

ğŸ“Š TOTAL: 64/66 successful runs across 33 blocks
ğŸ’¾ Results saved to: performance_profile.json
```

### ÙØ§ÛŒÙ„ performance_profile.json:

Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø´Ø§Ù…Ù„:
- Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ø± Ø¨Ù„Ø§Ú© Ø±ÙˆÛŒ CPU Ùˆ GPU
- Ø¢Ù…Ø§Ø± Ú©Ø§Ù…Ù„ (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†ØŒ Ø­Ø¯Ø§Ù‚Ù„ØŒ Ø­Ø¯Ø§Ú©Ø«Ø±)
- Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³ÛŒØ³ØªÙ… Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
- Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ scheduler

**Ù†Ú©ØªÙ‡**: Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ú©Ù‡ Ø³ÛŒØ³ØªÙ… Ø±Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ Ø­ØªÙ…Ø§Ù‹ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø±Ùˆ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯!