๐ฏ ฺฉุงุฑฺฉุฑุฏ ฺฉู ุณุณุชู:
ุงู ฺฉุฏ ฺฉ ุณุฑูุฑ ุชูุฒุน ุดุฏู ุจุฑุง ุงุฌุฑุง ูุฏูโูุง ุฒุจุงู ุจุฒุฑฺฏ (LLM) ุงุณุช ฺฉู ูุฏู ุฑุง ุจู ณณ ุจุฎุด (block) ุชูุณู ฺฉุฑุฏู ู ุขูโูุง ุฑุง ุฑู CPU/GPU ุงุฌุฑุง ูโฺฉูุฏ.

๐ ฺฉุชุงุจุฎุงููโูุง ู ฺฉุงุฑุจุฑุฏุดุงู:
๐ง ฺฉุชุงุจุฎุงููโูุง ุงุตู:
import onnxruntime as ort        # ุงุฌุฑุง ูุฏูโูุง ONNX ุฑู CPU/GPU
import websockets               # ุงุฑุชุจุงุท WebSocket ุจุง ฺฉูุงูุชโูุง
import asyncio                  # ุจุฑูุงููโููุณ ุบุฑููุฒูุงู
import numpy as np              # ูพุฑุฏุงุฒุด ุฏุงุฏูโูุง tensor
import json                     # ุณุฑุงูโุณุงุฒ ุฏุงุฏูโูุง

๐ง ฺฉุชุงุจุฎุงููโูุง ุณูุงุฑุด ูพุฑูฺู:
from worker_lib import CPUWorker, GPUWorker                    # ุงุฌุฑุงฺฉููุฏูโูุง CPU/GPU
from sequential_gpu_worker_lib import SequentialGPUWorker     # GPU worker ุจูููโุณุงุฒ ุดุฏู
from scheduler_lib import StaticSplitScheduler               # ุชูุณูโฺฉููุฏู ฺฉุงุฑ ุจู CPU/GPU
from serialization_utils import tensor_to_json_serializable  # ุชุจุฏู tensor ุจู JSON
from homf_lib import WarmStatePool                           # ูุฏุฑุช cache ูุฏูโูุง
from paged_kv_cache_lib import PagedKVCacheManager          # ูุฏุฑุช KV cache


โ๏ธ ูุฑุงุญู ฺฉุงุฑ ุณุณุชู:
1. ุฑุงูโุงูุฏุงุฒ (Initialization):
# ุจุงุฑฺฏุฐุงุฑ ุชูุธูุงุช ุดุจฺฉู
NETWORK_CONFIG = json.load(network_config.json)

# ุจุงุฑฺฏุฐุงุฑ ูุชุงุฏุชุง ูุฏู (33 ุจูุงฺฉ)
MODEL_CHAIN_ORDER = ["block_1", "block_2", ..., "block_33"]

# ุฑุงูโุงูุฏุงุฒ Workers
CPU_WORKER = CPUWorker()      # ุจุฑุง ูพุฑุฏุงุฒุด ุฑู CPU
GPU_WORKER = SequentialGPUWorker()  # ุจุฑุง ูพุฑุฏุงุฒุด ุฑู GPU

# ุชุนู ฺฉุฏุงู ุจูุงฺฉ ุฑู ฺฉุฏุงู worker ุงุฌุฑุง ุดูุฏ
EXECUTION_PLAN = {"block_1": "GPU", "block_2": "CPU", ...}

2. ุฏุฑุงูุช ุฏุฑุฎูุงุณุช ุงุฒ ฺฉูุงูุช:
# ฺฉูุงูุช ุฏุฑุฎูุงุณุช ูโูุฑุณุชุฏ:
{
  "session_id": "user_123",
  "step": 1,
  "input_tensors": {
    "input_ids": [1, 2, 3, ...],
    "attention_mask": [1, 1, 1, ...],
    "position_ids": [0, 1, 2, ...]
  }
}

3. ุงุฌุฑุง Pipeline (ณณ ุจูุงฺฉ):
for block_id in MODEL_CHAIN_ORDER:  # block_1 ุชุง block_33
    # ุขูุงุฏูโุณุงุฒ ูุฑูุฏ ุจุฑุง ูุฑ ุจูุงฺฉ
    block_inputs = prepare_block_inputs(block_id, previous_outputs)
    
    # ุชุนู worker (CPU ุง GPU)
    worker = GPU_WORKER if EXECUTION_PLAN[block_id] == "GPU" else CPU_WORKER
    
    # ุงุฌุฑุง ุจูุงฺฉ ุฑู worker
    result = await send_job_to_worker(worker, block_inputs)
    
    # ุงฺฏุฑ GPU ุดฺฉุณุช ุฎูุฑุฏุ ุฑู CPU ุงูุชุญุงู ฺฉู (Fallback)
    if result['status'] == 'error' and fallback_available:
        result = await send_job_to_worker(CPU_WORKER, block_inputs)
    
    # ุขูุงุฏูโุณุงุฒ ุฎุฑูุฌ ุจุฑุง ุจูุงฺฉ ุจุนุฏ
    previous_outputs = result['outputs']

4. ูุฏุฑุช ุฎุทุง ู Fallback:
# ุงฺฏุฑ GPU Worker ูุดฺฉู ุฏุงุดุช:
if GPU_fails:
    # ุฎูุฏฺฉุงุฑ ุจู CPU ุจุฑู
    EXECUTION_PLAN[block_id] = "CPU"  
    # ุณุน ูุฌุฏุฏ ุฑู CPU
    result = await CPU_WORKER.process(block_inputs)


๐ ุฎุฑูุฌโูุง ุณุณุชู:
โ ุฎุฑูุฌ ููููุชโุขูุฒ:
{
  "status": "success",
  "message": "Pipeline completed successfully",
  "session_id": "user_123",
  "step": 1,
  "outputs": {
    "logits": {
      "_tensor_": true,
      "dtype": "float16", 
      "shape": [1, 1, 32000],
      "data_b64": "base64_encoded_tensor_data..."
    }
  },
  "execution_times": {
    "block_1": 0.245,
    "block_2": 0.189,
    ...
    "block_33": 0.312
  },
  "total_pipeline_time": 8.74,
  "execution_stats": {
    "gpu_blocks_executed": 20,
    "cpu_blocks_executed": 13,
    "total_fallbacks": 3,
    "successful_fallbacks": 3
  },
  "fallback_events": [
    {
      "block_id": "block_15",
      "from": "GPU",
      "to": "CPU", 
      "reason": "gpu_memory_error",
      "success": true
    }
  ]
}

โ ุฎุฑูุฌ ุฎุทุง:
{
  "status": "error",
  "message": "Pipeline failed at block_12: GPU memory exhausted",
  "session_id": "user_123",
  "failed_block": "block_12",
  "error_type": "RuntimeError",
  "successful_blocks": ["block_1", "block_2", ..., "block_11"],
  "failed_blocks": [
    {
      "block_id": "block_12",
      "error": "GPU memory exhausted", 
      "execution_time": 2.45,
      "worker": "GPU"
    }
  ]
}


๐ฏ ูุซุงู ุนููฺฉุฑุฏ:
ูุฑูุฏ ููููู (ุงุฒ ฺฉูุงูุช):
{
  "session_id": "chat_001",
  "step": 1,
  "input_tensors": {
    "input_ids": {"_tensor_": true, "data": [1, 15043, 1234, 2]},
    "attention_mask": {"_tensor_": true, "data": [1, 1, 1, 1]},
    "position_ids": {"_tensor_": true, "data": [0, 1, 2, 3]}
  }
}

ุฎุฑูุฌ ููููู (ุจู ฺฉูุงูุช):
{
  "status": "success",
  "outputs": {
    "logits": {
      "_tensor_": true,
      "shape": [1, 4, 32000],
      "data_b64": "SGVsbG8gV29ybGQ..."
    }
  },
  "total_pipeline_time": 6.84,
  "execution_stats": {
    "gpu_blocks_executed": 25,
    "cpu_blocks_executed": 8,
    "avg_block_time": 0.207
  }
}


๐ ูุงฺฏโูุง ุณุณุชู:
{"timestamp": "2025-01-20T10:30:15", "event_type": "NODE_READY", "data": {"workers": {"cpu": true, "gpu": true}}}
{"timestamp": "2025-01-20T10:30:20", "event_type": "PIPELINE_EXECUTION_START", "data": {"blocks": 33}}
{"timestamp": "2025-01-20T10:30:22", "event_type": "BLOCK_EXECUTION_FALLBACK", "data": {"block": "block_15", "from": "GPU", "to": "CPU"}}
{"timestamp": "2025-01-20T10:30:28", "event_type": "PIPELINE_EXECUTION_COMPLETE", "data": {"time": 6.84}}


๐ ุฎูุงุตู:
ุงู ุณุณุชู ฺฉ inference engine ูพุดุฑูุชู ุจุฑุง ูุฏูโูุง LLM ุงุณุช ฺฉู:
โ ูุฏู ุฑุง ุจู ณณ ุจุฎุด ุชูุณู ูโฺฉูุฏ
โ ูุฑ ุจุฎุด ุฑุง ุฑู CPU ุง GPU ุงุฌุฑุง ูโฺฉูุฏ
โ ุฏุฑ ุตูุฑุช ูุดฺฉู GPUุ ุฎูุฏฺฉุงุฑ ุจู CPU ูโุฑูุฏ
โ ุงุฒ WebSocket ุจุฑุง ุงุฑุชุจุงุท ุงุณุชูุงุฏู ูโฺฉูุฏ
โ ุขูุงุฑ ฺฉุงูู ุงุฌุฑุง ู ุฎุทุงูุง ุฑุง ุงุฑุงุฆู ูโุฏูุฏ
โ ูุงุจูุช ุงุฌุฑุง ููุฒูุงู ฺูุฏู ุฏุฑุฎูุงุณุช ุฑุง ุฏุงุฑุฏ
ูุชุฌู ููุง: ุชููุฏ logits (ุงุญุชูุงูุงุช ฺฉููุงุช ุจุนุฏ) ุจุฑุง ูุฏู ุฒุจุงู! ๐


๐ ุงุฑุชุจุงุท ุจุง ฺฉุชุงุจุฎุงููโูุง ุณูุงุฑุด:
1. ๐ง worker_lib.py - ุงุฌุฑุงฺฉููุฏูโูุง ุงุตู
from worker_lib import CPUWorker, GPUWorker

# ฺฉุงุฑุจุฑุฏ:
CPU_WORKER = CPUWorker(
    name="CPUWorker",
    max_warm_sessions=3,
    execution_providers=['CPUExecutionProvider']
)

GPU_WORKER = GPUWorker(
    name="GPUWorker", 
    execution_providers=['DmlExecutionProvider', 'CPUExecutionProvider']
)

# ุงุฑุณุงู ฺฉุงุฑ:
job = {'block_id': 'block_1', 'input_data': tensors}
result = await send_job_to_worker(CPU_WORKER, job)

ฺู ฺฉุงุฑ ูโฺฉูุฏ: ูุฏูโูุง ONNX ุฑุง ุฑู CPU/GPU ุงุฌุฑุง ูโฺฉูุฏ

2. โก sequential_gpu_worker_lib.py - GPU Worker ุจููู
from sequential_gpu_worker_lib import SequentialGPUWorker

# ฺฉุงุฑุจุฑุฏ:
GPU_WORKER = SequentialGPUWorker(
    name="SequentialGPUWorker",
    max_retry_attempts=3,
    session_timeout=30.0,
    memory_cleanup_interval=5
)

# ูฺฺฏโูุง ุฎุงุต:
- Load/Unload pattern ุจุฑุง ุฌููฺฏุฑ ุงุฒ GPU memory leak
- Automatic fallback ุงุฒ DML ุจู CPU
- Memory cleanup ูพุณ ุงุฒ ูุฑ ฺูุฏ ุจูุงฺฉ

ฺู ฺฉุงุฑ ูโฺฉูุฏ: ูุฏุฑุช ููุดููุฏ GPU memory ู fallback ุฎูุฏฺฉุงุฑ

3. ๐ scheduler_lib.py - ุชูุณูโฺฉููุฏู ฺฉุงุฑ
from scheduler_lib import StaticSplitScheduler

# ฺฉุงุฑุจุฑุฏ:
scheduler = StaticSplitScheduler(
    profiling_file_path="profiling_results.json",
    model_chain_order=["block_1", "block_2", ..., "block_33"]
)

EXECUTION_PLAN = scheduler.generate_execution_plan()
# ุฎุฑูุฌ: {"block_1": "GPU", "block_2": "CPU", "block_3": "GPU", ...}

ฺู ฺฉุงุฑ ูโฺฉูุฏ: ุชุตูู ูโฺฏุฑุฏ ฺฉุฏุงู ุจูุงฺฉ ุฑู CPU ู ฺฉุฏุงู ุฑู GPU ุงุฌุฑุง ุดูุฏ

4. ๐ serialization_utils.py - ุชุจุฏู ุฏุงุฏูโูุง
from serialization_utils import tensor_to_json_serializable, json_serializable_to_tensor

# ุชุจุฏู numpy tensor ุจู JSON (ุจุฑุง ุงุฑุณุงู):
numpy_tensor = np.array([[1, 2, 3]], dtype=np.float16)
json_data = tensor_to_json_serializable(numpy_tensor)
# ุฎุฑูุฌ: {"_tensor_": true, "dtype": "float16", "shape": [1, 3], "data_b64": "..."}

# ุชุจุฏู JSON ุจู numpy tensor (ุจุฑุง ุฏุฑุงูุช):
tensor = json_serializable_to_tensor(json_data)
# ุฎุฑูุฌ: numpy array

ฺู ฺฉุงุฑ ูโฺฉูุฏ: ุชุจุฏู tensor ูุง ุจู ูุฑูุช JSON ุจุฑุง ุงุฑุณุงู ุฑู ุดุจฺฉู

5. ๐ homf_lib.py - ูุฏุฑุช Cache ูุฏูโูุง
from homf_lib import WarmStatePool, initialize_homf_globals

# ฺฉุงุฑุจุฑุฏ:
GLOBAL_HOMF_POOL = WarmStatePool(
    project_root_path=PROJECT_ROOT,
    network_config_global=NETWORK_CONFIG,
    model_metadata_global=metadata,
    max_warm_sessions=5,
    prefer_homf_format=True
)

# ูุฒุงุง:
- ูุฏูโูุง ุฑุง ูพุดโุจุงุฑฺฏุฐุงุฑ ูโฺฉูุฏ (warm cache)
- ุงุฒ ูุฑูุชโูุง ุจูููโุณุงุฒ ุดุฏู ุงุณุชูุงุฏู ูโฺฉูุฏ
- Load time ุฑุง ฺฉุงูุด ูโุฏูุฏ

ฺู ฺฉุงุฑ ูโฺฉูุฏ: ูุฏูโูุง ุฑุง ุฏุฑ memory ูฺฏู ูโุฏุงุฑุฏ ุชุง ุณุฑุนโุชุฑ ููุฏ ุดููุฏ

6. ๐พ paged_kv_cache_lib.py - ูุฏุฑุช KV Cache
from paged_kv_cache_lib import PagedKVCacheManager, SessionPagedKVCache

# ฺฉุงุฑุจุฑุฏ:
GLOBAL_PAGE_MANAGER = PagedKVCacheManager(
    initial_pages=16,
    page_capacity_tokens=16, 
    num_kv_heads=8,
    head_dim=128,
    dtype=np.float16
)

# ุจุฑุง ูุฑ session:
kv_cache = SessionPagedKVCache(session_id="user_123")

ฺู ฺฉุงุฑ ูโฺฉูุฏ: Key-Value cache ุจุฑุง transformer layers ูุฏุฑุช ูโฺฉูุฏ

7. ๐ custom_logging.py - ูุงฺฏโฺฏุฐุงุฑ ุณุงุฎุชุงุฑุงูุชู
from custom_logging import MainJsonFormatter, NODE_ID_FOR_LOGGING_HOLDER

# ฺฉุงุฑุจุฑุฏ:
json_formatter = MainJsonFormatter()
console_handler.setFormatter(json_formatter)

# ุฎุฑูุฌ ูุงฺฏ:
{
  "timestamp": "2025-01-20T10:30:15",
  "level": "INFO", 
  "event_type": "PIPELINE_EXECUTION_START",
  "node_id": "physical_node_1",
  "session_id": "user_123",
  "step": 1,
  "data": {"total_blocks": 33}
}

ฺู ฺฉุงุฑ ูโฺฉูุฏ: ูุงฺฏโูุง ุฑุง ุฏุฑ ูุฑูุช JSON ุณุงุฎุชุงุฑุงูุชู ุชููุฏ ูโฺฉูุฏ

๐ ุฌุฑุงู ฺฉุงุฑ ฺฉุงูู:
# 1. ุฏุฑุงูุช ุฏุฑุฎูุงุณุช WebSocket
async def handler(websocket):
    data = json.loads(message)
    
    # 2. ุชุจุฏู JSON ุจู tensor
    tensors = json_serializable_to_tensor(data['input_tensors'])
    
    # 3. ุงุฌุฑุง pipeline
    result = await execute_pipeline(session_id, step, tensors)
    
    # 4. ุชุจุฏู tensor ุจู JSON
    json_output = tensor_to_json_serializable(result['outputs'])
    
    # 5. ุงุฑุณุงู ูพุงุณุฎ
    await websocket.send(json.dumps(json_output))

# ุฌุฑุงู ุฏุงุฎู execute_pipeline:
for block_id in MODEL_CHAIN_ORDER:
    # ุงุฒ scheduler ุชุตูู ุจฺฏุฑ: CPU ุง GPUุ
    worker_type = EXECUTION_PLAN[block_id]
    
    # ฺฉุงุฑ ุฑุง ุจู worker ุงุฑุณุงู ฺฉู
    if worker_type == "GPU":
        result = await send_job_to_worker(GPU_WORKER, job_data)
    else:
        result = await send_job_to_worker(CPU_WORKER, job_data)
    
    # ุงฺฏุฑ ุดฺฉุณุช ุฎูุฑุฏุ fallback ฺฉู
    if result['status'] == 'error':
        result = await send_job_to_worker(CPU_WORKER, job_data)


๐ ุฎูุงุตู ูุงุจุณุชฺฏโูุง:
ฺฉุชุงุจุฎุงูู
ููุด
ูุฑูุฏ
ุฎุฑูุฌ
worker_lib
ุงุฌุฑุง ูุฏู
tensors
model outputs
sequential_gpu_worker_lib
GPU memory management
tensors
optimized outputs
scheduler_lib
ุชูุณู ฺฉุงุฑ
profiling data
execution plan
serialization_utils
ุชุจุฏู ุฏุงุฏู
numpy โ JSON
serialized data
homf_lib
cache ูุฏูโูุง
model paths
warm sessions
paged_kv_cache_lib
KV cache
transformer states
cached states
custom_logging
ูุงฺฏ structured
events
JSON logs

ูุฏู ฺฉู: ุงุฌุงุฏ ฺฉ ุณุณุชู inference ูพุงุฏุงุฑุ ูุงุจู ูุธุงุฑุช ู ุจููู ุจุฑุง ูุฏูโูุง LLM! ๐


๐๏ธ ููุง ฺฉู ูุนูุงุฑ {#ููุง-ฺฉู}
ุณุงุฎุชุงุฑ ฺฉู ูุฏู Llama-3.1-8B:
ุชุนุฏุงุฏ layers: 32 transformer layers + 1 output layer
ุชุนุฏุงุฏ blocks: 33 ุจูุงฺฉ ONNX
Architecture: Decoder-only transformer with causal attention
KV Cache: ูุฑ layer ฺฉุด ุฌุฏุงฺฏุงูู ุจุฑุง key/value ุฏุงุฑุฏ
ุชูุณูโุจูุฏ Blocks:
โโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโ
โ   Block 1   โโโโโถโ   Block 2   โโโโโถโ     ...     โโโโโถโ  Block 33   โ
โ (Layer 0 +  โ    โ  (Layer 1)  โ    โ(Layers 2-31)โ    โ(Output Head)โ
โ Embeddings) โ    โ             โ    โ             โ    โ             โ
โโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโ    โโโโโโโโโโโโโโโ

๐ธ Block 1: ูุฑูุฏ ู Layer ุงูู {#block-1}
ููุด:
Token embedding
Position embedding
Attention mask preprocessing
ุงููู transformer layer (layer 0)
Inputs ุฏูู:
ูุงู
Shape
ููุน
ุชูุถุญ
attention_mask
[batch_size, total_sequence_length]
int64
ูุงุณฺฉ ุชูุฌู (1=valid, 0=padding)
input_ids
[batch_size, sequence_length]
int64
ุดูุงุณู ุชูฺฉูโูุง (0-128255)
past_key_values.0.key
[batch_size, 8, past_seq_len, 128]
float16
ฺฉุด key layer 0 (ูุนูููุงู ุฎุงู ุฏุฑ ุดุฑูุน)
past_key_values.0.value
[batch_size, 8, past_seq_len, 128]
float16
ฺฉุด value layer 0 (ูุนูููุงู ุฎุงู ุฏุฑ ุดุฑูุน)
position_ids
[batch_size, sequence_length]
int64
ุดูุงุณู ูููุนุช (0, 1, 2, ...)

Outputs ุฏูู:
ูุงู
Shape
ููุน
ุชูุถุญ
/model/ScatterND_output_0
[batch_size, 1, total_seq_len, total_seq_len]
float16
ูุงุชุฑุณ attention ูพุฑุฏุงุฒุด ุดุฏู
/model/layers.0/Add_1_output_0
[batch_size, sequence_length, 4096]
float16
ุฎุฑูุฌ hidden state layer 0
/model/layers.0/self_attn/Unsqueeze_6_output_0
[batch_size, 1, total_seq_len, 128]
float16
ุงูฺฏู attention key
/model/layers.0/self_attn/Unsqueeze_7_output_0
[batch_size, 1, total_seq_len, 128]
float16
ุงูฺฏู attention value
present.0.key
[batch_size, 8, total_seq_len, 128]
float16
ฺฉุด ุฌุฏุฏ key layer 0
present.0.value
[batch_size, 8, total_seq_len, 128]
float16
ฺฉุด ุฌุฏุฏ value layer 0

ููููู Shapes (batch=1, seq=10, past=0):
python
# Inputs
attention_mask: [1, 10]
input_ids: [1, 10] 
past_key_values.0.key: [1, 8, 0, 128]    # ุฎุงู
past_key_values.0.value: [1, 8, 0, 128]  # ุฎุงู
position_ids: [1, 10]

# Outputs  
/model/ScatterND_output_0: [1, 1, 10, 10]
/model/layers.0/Add_1_output_0: [1, 10, 4096]
/model/layers.0/self_attn/Unsqueeze_6_output_0: [1, 1, 10, 128]
/model/layers.0/self_attn/Unsqueeze_7_output_0: [1, 1, 10, 128] 
present.0.key: [1, 8, 10, 128]
present.0.value: [1, 8, 10, 128]

๐ธ Blocks ูุงู (2-32): Transformer Layers {#blocks-ูุงู}
ููุด:
ูุฑ block ฺฉ transformer layer ฺฉุงูู (layers 1-31) ุฑุง ูพุงุฏูโุณุงุฒ ูโฺฉูุฏ
ุงูฺฏู ฺฉู Block N (N=2 ุชุง 32):



Inputs:
ูุงู
Shape
ููุน
ููุจุน
/model/ScatterND_output_0
[batch_size, 1, total_seq_len, total_seq_len]
float16
ุงุฒ Block 1 (ูุดุชุฑฺฉ ุจุฑุง ููู)
/model/layers.0/self_attn/Unsqueeze_6_output_0
[batch_size, 1, total_seq_len, 128]
float16
ุงุฒ Block 1 (ูุดุชุฑฺฉ ุจุฑุง ููู)
/model/layers.0/self_attn/Unsqueeze_7_output_0
[batch_size, 1, total_seq_len, 128]
float16
ุงุฒ Block 1 (ูุดุชุฑฺฉ ุจุฑุง ููู)
/model/layers.{N-2}/Add_1_output_0
[batch_size, sequence_length, 4096]
float16
ุงุฒ Block ูุจู
past_key_values.{N-1}.key
[batch_size, 8, past_seq_len, 128]
float16
ฺฉุด layer ูุนู
past_key_values.{N-1}.value
[batch_size, 8, past_seq_len, 128]
float16
ฺฉุด layer ูุนู

Outputs:
ูุงู
Shape
ููุน
ููุตุฏ
/model/layers.{N-1}/Add_1_output_0
[batch_size, sequence_length, 4096]
float16
ุจู Block ุจุนุฏ
present.{N-1}.key
[batch_size, 8, total_seq_len, 128]
float16
ฺฉุด ุจูโุฑูุฒุฑุณุงู ุดุฏู
present.{N-1}.value
[batch_size, 8, total_seq_len, 128]
float16
ฺฉุด ุจูโุฑูุฒุฑุณุงู ุดุฏู

ูุซุงู Block 2:
python
# Inputs
"/model/ScatterND_output_0": [1, 1, 10, 10]                    # ุงุฒ Block 1
"/model/layers.0/self_attn/Unsqueeze_6_output_0": [1, 1, 10, 128]  # ุงุฒ Block 1  
"/model/layers.0/self_attn/Unsqueeze_7_output_0": [1, 1, 10, 128]  # ุงุฒ Block 1
"/model/layers.0/Add_1_output_0": [1, 10, 4096]               # ุงุฒ Block 1
"past_key_values.1.key": [1, 8, 0, 128]                       # ุฎุงู
"past_key_values.1.value": [1, 8, 0, 128]                     # ุฎุงู

# Outputs
"/model/layers.1/Add_1_output_0": [1, 10, 4096]               # ุจู Block 3
"present.1.key": [1, 8, 10, 128]                              # ฺฉุด ุฌุฏุฏ
"present.1.value": [1, 8, 10, 128]                            # ฺฉุด ุฌุฏุฏ

๐ธ Block 33: ุฎุฑูุฌ ููุง {#block-33}
ููุด:
Language modeling head
ุชุจุฏู hidden states ุจู logits
ุชููุฏ ุงุญุชูุงูุงุช ุชูฺฉูโูุง
Inputs:
ูุงู
Shape
ููุน
ููุจุน
/model/layers.31/Add_1_output_0
[batch_size, sequence_length, 4096]
float16
ุงุฒ Block 32

Outputs:
ูุงู
Shape
ููุน
ุชูุถุญ
logits
[batch_size, sequence_length, 128256]
float16
ุงุญุชูุงูุงุช ุชูฺฉูโูุง (vocab_size=128256)

ูุซุงู:
python
# Input
"/model/layers.31/Add_1_output_0": [1, 10, 4096]

# Output  
"logits": [1, 10, 128256]  # ุขุฎุฑู ุชูฺฉู ุจุฑุง generation: logits[0, -1, :]

๐ Dependency Chain ฺฉุงูู {#dependency-chain}
Data Flow Pattern:
mermaid
graph TD
    A[Initial Inputs] --> B[Block 1]
    B --> B1[Global Attention Patterns]
    B --> B2[Hidden States Layer 0]
    B --> B3[KV Cache Layer 0]
    
    B1 --> C[Block 2]
    B2 --> C
    B3 --> C2[Past KV 1]
    C2 --> C
    
    C --> C1[Hidden States Layer 1]
    C --> C3[KV Cache Layer 1]
    
    C1 --> D[Block 3]
    B1 --> D
    C3 --> D2[Past KV 2]
    D2 --> D
    
    D --> E[...]
    E --> F[Block 32]
    F --> F1[Hidden States Layer 31]
    F1 --> G[Block 33]
    G --> H[Logits]
ูุณุฑ ุงูุชูุงู ุฏุงุฏูโูุง:
Global Patterns (ุงุฒ Block 1 ุจู ููู):
/model/ScatterND_output_0
/model/layers.0/self_attn/Unsqueeze_6_output_0
/model/layers.0/self_attn/Unsqueeze_7_output_0
Sequential Hidden States:
 Block 1 โ /model/layers.0/Add_1_output_0 โ Block 2
Block 2 โ /model/layers.1/Add_1_output_0 โ Block 3
...
Block 32 โ /model/layers.31/Add_1_output_0 โ Block 33


KV Cache Chain:
 Block N: present.{N-1}.key/value โ past_key_values.{N}.key/value (Block N+1)



๐ Data Flow Mapping {#data-flow-mapping}
Mapping Function:
python
def map_block_outputs_to_next_inputs(current_block_id: int, outputs: Dict[str, np.ndarray], 
                                   global_cache: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
    """
    ููุดูโุจุฑุฏุงุฑ ุฎุฑูุฌโูุง ฺฉ ุจูุงฺฉ ุจู ูุฑูุฏโูุง ุจูุงฺฉ ุจุนุฏ
    
    Args:
        current_block_id: ุดูุงุฑู ุจูุงฺฉ ูุนู (1-33)
        outputs: ุฎุฑูุฌโูุง ุจูุงฺฉ ูุนู
        global_cache: ฺฉุด global patterns ุงุฒ Block 1
        
    Returns:
        mapped_inputs: ูุฑูุฏโูุง ุขูุงุฏู ุจุฑุง ุจูุงฺฉ ุจุนุฏ
    """
    
    next_block_id = current_block_id + 1
    mapped_inputs = {}
    
    if current_block_id == 1:
        # ุฐุฎุฑู global patterns ุจุฑุง ุงุณุชูุงุฏู ุฏุฑ ุชูุงู ุจูุงฺฉโูุง
        global_cache.update({
            "/model/ScatterND_output_0": outputs["/model/ScatterND_output_0"],
            "/model/layers.0/self_attn/Unsqueeze_6_output_0": outputs["/model/layers.0/self_attn/Unsqueeze_6_output_0"],
            "/model/layers.0/self_attn/Unsqueeze_7_output_0": outputs["/model/layers.0/self_attn/Unsqueeze_7_output_0"]
        })
        
        if next_block_id <= 32:
            # ุจุฑุง Block 2
            mapped_inputs = {
                "/model/ScatterND_output_0": outputs["/model/ScatterND_output_0"],
                "/model/layers.0/self_attn/Unsqueeze_6_output_0": outputs["/model/layers.0/self_attn/Unsqueeze_6_output_0"],
                "/model/layers.0/self_attn/Unsqueeze_7_output_0": outputs["/model/layers.0/self_attn/Unsqueeze_7_output_0"],
                "/model/layers.0/Add_1_output_0": outputs["/model/layers.0/Add_1_output_0"],
                "past_key_values.1.key": np.zeros_like(outputs["present.0.key"])[:, :, :0, :],  # ุฎุงู
                "past_key_values.1.value": np.zeros_like(outputs["present.0.value"])[:, :, :0, :]  # ุฎุงู
            }
    
    elif 2 <= current_block_id <= 31:
        # ุจูุงฺฉโูุง ูุงู
        layer_num = current_block_id - 1  # layer number (1-30)
        
        if next_block_id <= 32:
            mapped_inputs = {
                # Global patterns ุงุฒ Block 1
                "/model/ScatterND_output_0": global_cache["/model/ScatterND_output_0"],
                "/model/layers.0/self_attn/Unsqueeze_6_output_0": global_cache["/model/layers.0/self_attn/Unsqueeze_6_output_0"],
                "/model/layers.0/self_attn/Unsqueeze_7_output_0": global_cache["/model/layers.0/self_attn/Unsqueeze_7_output_0"],
                
                # Hidden state ุงุฒ ุจูุงฺฉ ูุนู
                f"/model/layers.{layer_num}/Add_1_output_0": outputs[f"/model/layers.{layer_num}/Add_1_output_0"],
                
                # Past KV cache (ุฎุงู ุจุฑุง layer ุฌุฏุฏ)
                f"past_key_values.{next_block_id-1}.key": np.zeros_like(outputs[f"present.{layer_num}.key"])[:, :, :0, :],
                f"past_key_values.{next_block_id-1}.value": np.zeros_like(outputs[f"present.{layer_num}.value"])[:, :, :0, :]
            }
        elif next_block_id == 33:
            # ุจุฑุง Block 33 (ููุท hidden state ูุงุฒู)
            mapped_inputs = {
                f"/model/layers.{layer_num}/Add_1_output_0": outputs[f"/model/layers.{layer_num}/Add_1_output_0"]
            }
    
    elif current_block_id == 32:
        # Block 32 ุจู Block 33
        mapped_inputs = {
            "/model/layers.31/Add_1_output_0": outputs["/model/layers.31/Add_1_output_0"]
        }
    
    return mapped_inputs
KV Cache Management:
python
def manage_kv_cache(block_id: int, outputs: Dict[str, np.ndarray], 
                   kv_cache_storage: Dict[str, np.ndarray]) -> None:
    """
    ูุฏุฑุช KV Cache ุจุฑุง ุงุณุชูุงุฏู ุฏุฑ generation ุจุนุฏ
    
    Args:
        block_id: ุดูุงุฑู ุจูุงฺฉ (1-32)
        outputs: ุฎุฑูุฌโูุง ุจูุงฺฉ ุดุงูู present keys/values
        kv_cache_storage: ุฐุฎุฑูโุณุงุฒ ฺฉุด ุจุฑุง ุงุณุชูุงุฏู ุจุนุฏ
    """
    
    if block_id <= 32:
        layer_num = block_id - 1
        
        # ุฐุฎุฑู present cache ุจุฑุง ุงุณุชูุงุฏู ุฏุฑ generation ุจุนุฏ
        if f"present.{layer_num}.key" in outputs:
            kv_cache_storage[f"layer_{layer_num}_key"] = outputs[f"present.{layer_num}.key"]
            kv_cache_storage[f"layer_{layer_num}_value"] = outp


ุชุญูู ูุงู ูุงฺฏ all_blocks_test_log.txt
ุงู ูุงู ูุงฺฏุ ูุชุงุฌ ุชุณุช ุนููฺฉุฑุฏ ูุฑ ฺฉ ุงุฒ ณณ ุจูุงฺฉ ูุฏู ONNX ุฑุง ุจู ุตูุฑุช ุฌุฏุงฺฏุงูู (ุจุง batch_size=5, seq_len=10, past_seq=0) ูุดุงู ูโุฏูุฏ.
ฑ. ุฎูุงุตู ฺฉู ุชุณุช (Overall Test Summary)
ุชุนุฏุงุฏ ฺฉู ุจูุงฺฉโูุง ุชุณุช ุดุฏู: ณณ
ุจูุงฺฉโูุง ูููู: ณณ
ุจูุงฺฉโูุง ูุงูููู: ฐ
ูุชุฌู ููุง: ุชูุงู ณณ ุจูุงฺฉ ุจุง ููููุช ุชุณุช ุดุฏูโุงูุฏ.
ุงู ูุชุงุฌ ูุดุงู ูโุฏูุฏ ฺฉู ูุฑ ุจูุงฺฉ ONNX ุจู ุตูุฑุช ูุณุชูู ูุงุฏุฑ ุจู ุจุงุฑฺฏุฐุงุฑุ ุฏุฑุงูุช ูุฑูุฏโูุง ุณุงุฎุชฺฏ ุจุง ุดฺฉูโูุง ุตุญุญ ู ุงุฌุฑุง ุงุณุชูุชุงุฌ ุจุฏูู ุฎุทุง ุงุณุช.
ฒ. ุชุญูู ุฌุฒุฆุงุช ุจูุงฺฉโูุง
ูุงฺฏุ ุฌุฒุฆุงุช ูุฑูุฏโูุง ู ุฎุฑูุฌโูุง ูุฑ ุจูุงฺฉ ุฑุง ุงุฒ ฺฏุฑุงู ONNX ู ููฺูู ุดฺฉูโูุง ูุงูุน (Concrete Shapes) ฺฉู ุจุฑุง ูุฑูุฏโูุง ุณุงุฎุชฺฏ ุงุณุชูุงุฏู ุดุฏูโุงูุฏุ ูุดุงู ูโุฏูุฏ. ุชูุถุญุงุช ูุงุฑุณ ุฏุฑ ูุงฺฏ ููฺฉู ุงุณุช ุจู ุฏูู ูุดฺฉูุงุช ฺฉุฏฺฏุฐุงุฑ ฺฉู ูุงูุฑุชุจ ุจุงุดูุฏุ ุงูุง ูุนู ฺฉู ุขูโูุง ูุงุจู ุฏุฑฺฉ ุงุณุช.
ุงูู. ุจูุงฺฉ ฑ: block_1.onnx (ูพุฑุฏุงุฒุด ุงููู ู ูุงู ุชุฑูุณููุฑูุฑ ฐ)
ุงู ุจูุงฺฉ ูุณุฆูู ูพุฑุฏุงุฒุด ูุฑูุฏโูุง ุงููู ูุฏู ุงุณุช.
ูพุงุฑุงูุชุฑูุง ุชุณุช: batch_size=5, seq_len=10, past_seq=0
ูุฑูุฏโูุง ูุฏู (ุงุฒ ฺฏุฑุงู ONNX):
attention_mask: tensor(int64), Shape: [None, None], (ูุงุณฺฉ ุชูุฌู)
input_ids: tensor(int64), Shape: [None, None], (ุดูุงุณู ุชูฺฉูโูุง)
past_key_values.0.key: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด key ูุงู ฐ)
past_key_values.0.value: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด value ูุงู ฐ)
position_ids: tensor(int64), Shape: [None, None], (ุดูุงุณู ูููุนุช)
ุฎุฑูุฌโูุง ูุฏู (ุงุฒ ฺฏุฑุงู ONNX):
/model/ScatterND_output_0: tensor(float16), Shape: [None, None, None, None], (ูุงุชุฑุณ attention ูพุฑุฏุงุฒุด ุดุฏู)
/model/layers.0/Add_1_output_0: tensor(float16), Shape: [None, None, 4096], (ุฎุฑูุฌ hidden state ูุงู ฐ)
/model/layers.0/self_attn/Unsqueeze_6_output_0: tensor(float16), Shape: [None, 1, None, 128], (ุงูฺฏู attention key)
/model/layers.0/self_attn/Unsqueeze_7_output_0: tensor(float16), Shape: [None, 1, None, 128], (ุงูฺฏู attention value)
present.0.key: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด ุฌุฏุฏ key ูุงู ฐ)
present.0.value: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด ุฌุฏุฏ value ูุงู ฐ)
ูุฑูุฏโูุง ุณุงุฎุชฺฏ ุงุฌุงุฏ ุดุฏู:
attention_mask: Original Shape=[None, None] -> Concrete Shape=[5, 10]
input_ids: Original Shape=[None, None] -> Concrete Shape=[5, 10]
past_key_values.0.key: Original Shape=[None, 8, None, 128] -> Concrete Shape=[5, 8, 0, 128] (ุฎุงูุ ุฒุฑุง past_seq=0)
past_key_values.0.value: Original Shape=[None, 8, None, 128] -> Concrete Shape=[5, 8, 0, 128] (ุฎุงูุ ุฒุฑุง past_seq=0)
position_ids: Original Shape=[None, None] -> Concrete Shape=[5, 10]
ุฎุฑูุฌโูุง ุงุณุชูุชุงุฌ ูุงูุน:
/model/ScatterND_output_0: Shape: (5, 1, 10, 10), Dtype: float16
/model/layers.0/Add_1_output_0: Shape: (5, 10, 4096), Dtype: float16
/model/layers.0/self_attn/Unsqueeze_6_output_0: Shape: (5, 1, 10, 128), Dtype: float16
/model/layers.0/self_attn/Unsqueeze_7_output_0: Shape: (5, 1, 10, 128), Dtype: float16
present.0.key: Shape: (5, 8, 10, 128), Dtype: float16
present.0.value: Shape: (5, 8, 10, 128), Dtype: float16
ุจ. ุจูุงฺฉโูุง ูุงู (ฒ ุชุง ณฒ): ูุงูโูุง ุชุฑูุณููุฑูุฑ
ุงู ุจูุงฺฉโูุง ูุงูโูุง ูุงู ุชุฑูุณููุฑูุฑ (ูุงู ฑ ุชุง ูุงู ณฑ) ุฑุง ูพุงุฏูโุณุงุฒ ูโฺฉููุฏ. ูุฑ ุจูุงฺฉุ ุฎุฑูุฌ hidden state ู key/value caches ุฑุง ุงุฒ ูุงู ูุจู ุฏุฑุงูุช ูโฺฉูุฏ ู hidden state ู key/value caches ุจูโุฑูุฒ ุดุฏู ุฑุง ุจู ูุงู ุจุนุฏ ููุชูู ูโฺฉูุฏ.
ูพุงุฑุงูุชุฑูุง ุชุณุช: batch_size=5, seq_len=10, past_seq=0 (ุจุฑุง ูุฑ ุจูุงฺฉ ุจู ุตูุฑุช ูุฌุฒุง ุชุณุช ุดุฏูโุงูุฏ)
ุงูฺฏู ฺฉู ูุฑูุฏโูุง ูุฏู (ุงุฒ ฺฏุฑุงู ONNX) ุจุฑุง block_N.onnx (N ุงุฒ ฒ ุชุง ณฒ):
/model/ScatterND_output_0: tensor(float16), Shape: [], (ูุงุชุฑุณ attention ูพุฑุฏุงุฒุด ุดุฏู - ุงุฒ Block 1)
/model/layers.0/self_attn/Unsqueeze_6_output_0: tensor(float16), Shape: [], (ุงูฺฏู attention key - ุงุฒ Block 1)
/model/layers.0/self_attn/Unsqueeze_7_output_0: tensor(float16), Shape: [], (ุงูฺฏู attention value - ุงุฒ Block 1)
/model/layers.{N-2}/Add_1_output_0: tensor(float16), Shape: [None, None, 4096], (ุฎุฑูุฌ hidden state ูุงู N-2 - ุงุฒ ุจูุงฺฉ ูุจู)
past_key_values.{N-1}.key: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด key ูุงู N-1)
past_key_values.{N-1}.value: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด value ูุงู N-1)
ุงูฺฏู ฺฉู ุฎุฑูุฌโูุง ูุฏู (ุงุฒ ฺฏุฑุงู ONNX) ุจุฑุง block_N.onnx (N ุงุฒ ฒ ุชุง ณฒ):
/model/layers.{N-1}/Add_1_output_0: tensor(float16), Shape: [None, None, 4096], (ุฎุฑูุฌ hidden state ูุงู N-1)
present.{N-1}.key: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด ุฌุฏุฏ key ูุงู N-1)
present.{N-1}.value: tensor(float16), Shape: [None, 8, None, 128], (ฺฉุด ุฌุฏุฏ value ูุงู N-1)
ูุฑูุฏโูุง ุณุงุฎุชฺฏ ุงุฌุงุฏ ุดุฏู ุจุฑุง block_N.onnx (ูุซุงู block_2.onnx):
/model/ScatterND_output_0: Original Shape=[] -> Concrete Shape=[5, 1, 10, 10]
/model/layers.0/Add_1_output_0: Original Shape=[None, None, 4096] -> Concrete Shape=[5, 10, 4096]
/model/layers.0/self_attn/Unsqueeze_6_output_0: Original Shape=[] -> Concrete Shape=[5, 1, 10, 128]
/model/layers.0/self_attn/Unsqueeze_7_output_0: Original Shape=[] -> Concrete Shape=[5, 1, 10, 128]
past_key_values.1.key: Original Shape=[None, 8, None, 128] -> Concrete Shape=[5, 8, 0, 128]
past_key_values.1.value: Original Shape=[None, 8, None, 128] -> Concrete Shape=[5, 8, 0, 128]
ุฎุฑูุฌโูุง ุงุณุชูุชุงุฌ ูุงูุน ุจุฑุง block_N.onnx (ูุซุงู block_2.onnx):
/model/layers.1/Add_1_output_0: Shape: (5, 10, 4096), Dtype: float16
present.1.key: Shape: (5, 8, 10, 128), Dtype: float16
present.1.value: Shape: (5, 8, 10, 128), Dtype: float16
ุงู ุงูฺฏู ุจุฑุง ุชูุงู ุจูุงฺฉโูุง ูุงู (ฒ ุชุง ณฒ) ุชฺฉุฑุงุฑ ูโุดูุฏุ ุจุง ุงู ุชูุงูุช ฺฉู ุดูุงุฑู ูุงู ุฏุฑ ูุงู ุชูุณูุฑูุง (/model/layers.X/ ู past_key_values.X.) ุจุง ูพุดุฑูุช ุจูุงฺฉโูุง ุงูุฒุงุด ูโุงุจุฏ.
ูพ. ุจูุงฺฉ ณณ: block_33.onnx (ูุงู ููุง ู ุฎุฑูุฌ)
ุงู ุจูุงฺฉ ุขุฎุฑู ูุงู ุชุฑูุณููุฑูุฑ (ูุงู ณฒ) ุฑุง ูพุงุฏูโุณุงุฒ ูโฺฉูุฏ ู ุฎุฑูุฌ ููุง ูุฏู (logits) ุฑุง ุชููุฏ ูโฺฉูุฏ.
ูพุงุฑุงูุชุฑูุง ุชุณุช: batch_size=5, seq_len=10, past_seq=0
ูุฑูุฏโูุง ูุฏู (ุงุฒ ฺฏุฑุงู ONNX):
/model/layers.31/Add_1_output_0: tensor(float16), Shape: [None, None, 4096], (ุฎุฑูุฌ hidden state ูุงู ณฑ)
ุฎุฑูุฌโูุง ูุฏู (ุงุฒ ฺฏุฑุงู ONNX):
logits: tensor(float16), Shape: [None, None, 128256], (ุฎุฑูุฌ ููุง ูุฏู)
ูุฑูุฏโูุง ุณุงุฎุชฺฏ ุงุฌุงุฏ ุดุฏู:
/model/layers.31/Add_1_output_0: Original Shape=[None, None, 4096] -> Concrete Shape=[5, 10, 4096]
ุฎุฑูุฌโูุง ุงุณุชูุชุงุฌ ูุงูุน:
logits: Shape: (5, 10, 128256), Dtype: float16
ณ. ูุชุฌูโฺฏุฑ ู ุชุญูู ูุงุจุณุชฺฏโูุง ุจุฑุง ูพุงูพโูุงู
ููููุช ฺฉุงูู: ุชูุงู ุจูุงฺฉโูุง ุจู ุตูุฑุช ูุณุชูู ุจุง ููููุช ุชุณุช ุดุฏูโุงูุฏุ ฺฉู ูุดุงูโุฏููุฏู ุณูุงูุช ูุงูโูุง ONNX ู ูุงุจูุช ุขูโูุง ุจุฑุง ุงุฌุฑุง ุงุณุชูุชุงุฌ ุงุณุช.
ูุฏุฑุช ุดฺฉูโูุง ุฏูุงูฺฉ: ุชุงุจุน get_concrete_shape ุจู ุฏุฑุณุช ุดฺฉูโูุง ุฏูุงูฺฉ (None ุง -1) ุฑุง ุจู ุดฺฉูโูุง ูุดุฎุต (Concrete Shapes) ุจุฑ ุงุณุงุณ batch_size, seq_len, ู past_seq ุชุจุฏู ฺฉุฑุฏู ุงุณุช. ุงู ุจุฑุง ุงุทููุงู ุงุฒ ุงูฺฉู ูุฑูุฏโูุง ุณุงุฎุชฺฏ ุจุง ุงุจุนุงุฏ ุตุญุญ ุจู ูุฏู ุฏุงุฏู ูโุดููุฏุ ุญุงุช ุงุณุช.
ูุงุจุณุชฺฏโูุง ุจู ุจูุงฺฉโูุง:
block_1.onnx: ุงู ุจูุงฺฉ ูุฑูุฏโูุง ุงููู ูุฏู (attention_mask, input_ids, position_ids) ุฑุง ูโฺฏุฑุฏ ู ุฎุฑูุฌโูุง ุงููู ุชุฑูุณููุฑูุฑ (ุดุงูู hidden state ูุงู ฐุ ุงูฺฏููุง attention ู ฺฉุดโูุง key/value ุงููู) ุฑุง ุชููุฏ ูโฺฉูุฏ.
ุจูุงฺฉโูุง ูุงู (block_2.onnx ุชุง block_32.onnx):
ุงู ุจูุงฺฉโูุง ุจู hidden state ุงุฒ ุจูุงฺฉ ูุจู (ูุซูุงู /model/layers.X/Add_1_output_0) ู ููฺูู ุงูฺฏููุง attention ุงุฒ block_1 (ูุงููุฏ /model/ScatterND_output_0, /model/layers.0/self_attn/Unsqueeze_X_output_0) ู ฺฉุดโูุง past_key_values ูุฑุจูุท ุจู ูุงู ุฎูุฏุดุงู ูุงุจุณุชู ูุณุชูุฏ.
ุฎุฑูุฌโูุง ุงุตู ุขูโูุง ูุฒ hidden state ุจุฑุง ุจูุงฺฉ ุจุนุฏ ู ฺฉุดโูุง present.key/value ุจูโุฑูุฒ ุดุฏู ุจุฑุง ุงุณุชูุงุฏู ุฏุฑ ฺฏุงู ุฒูุงู ุจุนุฏ ุงุณุช.
block_33.onnx: ุงู ุจูุงฺฉ ุขุฎุฑู hidden state ุฑุง ุงุฒ block_32 ุฏุฑุงูุช ูโฺฉูุฏ ู logits (ุฎุฑูุฌ ููุง ูุฏู) ุฑุง ุชููุฏ ูโฺฉูุฏ.
ููุด past_key_values ู present.key/value: ุงู ุชูุณูุฑูุง ุจุฑุง ูุฏุฑุช ุญุงูุธู ุฏุฑ ูุฏูโูุง ุชุฑูุณููุฑูุฑ (ฺฉุด ฺฉุฑุฏู ูุญุงุณุจุงุช attention ุงุฒ ุชูฺฉูโูุง ูุจู) ุถุฑูุฑ ูุณุชูุฏ. ุฏุฑ ุงู ุชุณุชุ past_seq=0 ุจูุฏูุ ุจูุงุจุฑุงู ูุฑูุฏโูุง past_key_values ุฎุงู ูุณุชูุฏ ู ุฎุฑูุฌโูุง present.key/value ุดุงูู ฺฉุดโูุง ุฌุฏุฏ ุจุฑุง ุชูฺฉูโูุง ูุนู (ุจุง ุทูู seq_len) ูุณุชูุฏ. ุฏุฑ ฺฉ ูพุงูพโูุงู ุงุณุชูุชุงุฌ ุชูุงูโฺฏุฑุง ูุงูุนุ present.key/value ุงุฒ ฺฉ ฺฏุงู ุฒูุงู ุจู ุนููุงู past_key_values ุจุฑุง ฺฏุงู ุฒูุงู ุจุนุฏ ุงุณุชูุงุฏู ูโุดูุฏ.
ุงู ุชุญูู ุฌุฒุฆุงุช ฺฉุงู ุฑุง ุจุฑุง ุฏุฑฺฉ ุฌุฑุงู ุฏุงุฏูโูุง ู ูุงุจุณุชฺฏโูุง ุจู ุจูุงฺฉโูุง ุฏุฑ ูุฏู ุดูุง ูุฑุงูู ูโฺฉูุฏ ู ูโุชูุงูุฏ ุจู ุดูุง ุฏุฑ ุทุฑุงุญ ู ูพุงุฏูโุณุงุฒ ูพุงูพโูุงู ุงุณุชูุชุงุฌ ฺฉูฺฉ ฺฉูุฏ.






๐ homf_lib.py
ูุฏู: ุจุงุฑฺฏุฐุงุฑ ุณุฑุน ู ฺฉุด ฺฉุฑุฏู ูุฏูโูุง ONNXฺฉูุงุณ ุงุตู: WarmStatePoolูุชุฏูุง ฺฉูุฏ:__init__(): ุชูุธูุงุช ุงููู poolุ ุชุนู execution providersget_session_ultra_fast(): ุฏุฑุงูุช ุณุดู ONNX ุงุฒ cache ุง ุจุงุฑฺฏุฐุงุฑ ุฌุฏุฏexecute_session_with_homf_cache(): ุงุฌุฑุง inference ุจุง ูุฏุฑุช cache_load_session_with_mmap_weights(): ุจุงุฑฺฏุฐุงุฑ ุจุง memory-mapped weights_evict_oldest_session(): ุญุฐู ูุฏูโุชุฑู ุณุดู (LRU)ูฺฺฏ ุฎุงุต: ุงุณุชูุงุฏู ุงุฒ ุชฺฉูฺฉโูุง ุจุงุฑฺฏุฐุงุฑ ุณุฑุน (mmap, skeleton models)
๐ worker_lib.py
ูุฏู: ุงุฌุงุฏ ฺฉุงุฑฺฏุฑูุง ูุณุชูู ุจุฑุง ุงุฌุฑุง ูุฏู ุฑู CPU ุง GPUฺฉูุงุณโูุง:BaseWorkerูุชุฏูุง ุงุตู:run(): ุญููู ุงุตู - ููุชุธุฑ job ุงุฒ inboxุ ูพุฑุฏุงุฒุดุ ุงุฑุณุงู ูุชุฌู_process_job(): ุฏุฑุงูุช ุณุดู ุงุฒ HOMFุ ุงุฌุฑุง inferenceุ ุจุงุฒฺฏุดุช ูุชุงุฌshutdown(): ุฎุงุชูู gracefulCPUWorker ู GPUWorkerููุท execution_providers ูุชูุงูุช ุฏุงุฑูุฏCPU: ['CPUExecutionProvider']GPU: ['DmlExecutionProvider', 'CPUExecutionProvider']ูฺฺฏ: ุงุณุชูุงุฏู ุงุฒ ThreadPoolExecutor ุจุฑุง ุฌููฺฏุฑ ุงุฒ blocking
๐ scheduler_lib.py
ูุฏู: ุชุนู ุจูุชุฑู ูุญูู ุชูุณู ุจูุงฺฉโูุง ุจู CPU ู GPUฺฉูุงุณ: StaticSplitSchedulerูุชุฏูุง ููู:__init__(): ุจุงุฑฺฏุฐุงุฑ performance profilegenerate_execution_plan(): ูุญุงุณุจู ููุทู ุชูุณู ุจููู (k)ุชุณุช ููู ุญุงูุงุช: k=0 ุชุง k=33ูุญุงุณุจู ุฒูุงู: pipeline_time = max(cpu_time, gpu_time)ุงูุชุฎุงุจ k ุจุง ฺฉูุชุฑู pipeline_timeget_worker_for_block(): ูุดุฎุต ฺฉุฑุฏู worker ุจุฑุง ูุฑ ุจูุงฺฉget_execution_summary(): ุขูุงุฑ ู ุฎูุงุตู planุฎุฑูุฌ: ุฏฺฉุดูุฑ {"block_1": "CPU", "block_2": "CPU", ..., "block_20": "GPU"}
๐ model_node.py
ูุฏู: ุณุฑูุฑ ุงุตู WebSocket ู ูุฏุฑุช pipelineุชูุงุจุน ฺฉูุฏ:handler()ุฏุฑุงูุช ุฏุฑุฎูุงุณุช WebSocketูุฑุงุฎูุงู execute_pipeline()ุงุฑุณุงู ูพุงุณุฎ ููุงexecute_pipeline()ูุฑุงุญู:ุจุฑุฑุณ ููุฏุงุฑุฏู ุงูููdeserialize ูุฑูุฏโูุงุญููู ุฑู ููู ุจูุงฺฉโูุง:ุชุนู worker ุงุฒ EXECUTION_PLANุขูุงุฏูโุณุงุฒ inputs (hidden states, KV cache)ุงุฑุณุงู job ุจู workerุงูุชุธุงุฑ ุจุฑุง ูุชุฌูุฐุฎุฑู outputs ุจุฑุง ุจูุงฺฉ ุจุนุฏุจุงุฒฺฏุดุช ูุชุฌู ููุงmain_server()ุจุงุฑฺฏุฐุงุฑ ุชูุธูุงุชุงุฌุงุฏ workers ู schedulerุฑุงูโุงูุฏุงุฒ WebSocket serverูุชุบุฑูุง global ููู:EXECUTION_PLAN: ููุดู ุชูุณู ุจูุงฺฉโูุงCPU_WORKER, GPU_WORKER: ูููููโูุง workerGLOBAL_HOMF_POOL: ูุฏุฑุช cache ูุฏูโูุง
๐ serialization_utils.py
ูุฏู: ุชุจุฏู numpy arrays ุจู/ุงุฒ JSONุชูุงุจุน:tensor_to_json_serializable(tensor){
    "_tensor_": True,
    "dtype": "float32",
    "shape": [1, 6, 4096],
    "data_b64": "base64_encoded_bytes..."
}json_serializable_to_tensor(data)ุจุฑุฑุณ ูุฌูุฏ _tensor_ flagdecode ฺฉุฑุฏู base64ุจุงุฒุณุงุฒ numpy array ุจุง shape ู dtype ุตุญุญฺฉุงุฑุจุฑุฏ: ุงุฑุณุงู tensors ุฏุฑ WebSocket (JSON ููโุชูุงูุฏ ูุณุชููุงู numpy array ุฑุง handle ฺฉูุฏ)
sequential_gpu_worker_lib.py
ูพุงุฏูโุณุงุฒ SequentialGPUWorker (ูุฑฺฉุฑ GPU ุชุฑุชุจ)
ฺฉูุงุณ SequentialGPUWorker ฺฉ ุฌุฒุก ุญุงุช ุจุฑุง ูุฏุฑุช ุงุณุชูุชุงุฌ ูุฏูโูุง ููุด ูุตููุน (ONNX) ุฑู ุณุฎุชโุงูุฒุงุฑ GPU ู CPU ุงุณุช. ูุฏู ุงุตู ุขู ุงุทููุงู ุงุฒ ูพุงุฏุงุฑ ู ูุงุจูุช ุงุทููุงู ุจุงูุง ุฏุฑ ุงุฌุฑุง ูุฏูโูุงุณุชุ ุญุช ุฏุฑ ููุงุฌูู ุจุง ุฎุทุงูุง ุณุฎุชโุงูุฒุงุฑ ุง ฺฉูุจูุฏ ููุงุจุน.
ูฺฺฏโูุง ฺฉูุฏ:
ูุฏุฑุช ููุดููุฏ ููุงุจุน GPU: ุงู ูุฑฺฉุฑ ูุฏูโูุง ุฑุง ููุท ุฏุฑ ุตูุฑุช ูุงุฒ ุจุงุฑฺฏุฐุงุฑ (Load) ู ูพุณ ุงุฒ ุงุณุชูุงุฏูุ ุชุฎูู (Unload) ูโฺฉูุฏ. ุงู ุฑูฺฉุฑุฏ "Load/Unload pattern" ุจู ุจูููโุณุงุฒ ูุตุฑู ุญุงูุธู GPU ฺฉูฺฉ ฺฉุฑุฏู ู ุงุฒ ุงุดุบุงู ุจโููุฑุฏ ููุงุจุน ุฌููฺฏุฑ ูโฺฉูุฏ.
ุณุณุชู ูุงูโุจฺฉ (Fallback) ูู: ุฏุฑ ุตูุฑุช ฺฉู ุจุงุฑฺฏุฐุงุฑ ุง ุงุฌุฑุง ูุฏู ุฑู GPU ุจุง ุฎุทุง ููุงุฌู ุดูุฏ (ูุซูุงู ุจู ุฏูู ูุดฺฉูุงุช ุฏุฑุงูุฑ ุง ุญุงูุธู)ุ ูุฑฺฉุฑ ุจู ุทูุฑ ุฎูุฏฺฉุงุฑ ุชูุงุด ูโฺฉูุฏ ุชุง ุงุฒ ุณุงุฑ GPU Providers (ูุซู DML ุง CUDA) ู ุฏุฑ ููุงุช ุงุฒ CPU ุจุฑุง ุงุฌุฑุง ูุฏู ุงุณุชูุงุฏู ฺฉูุฏ. ุงู ูุงุจูุชุ ููุงููุช ุฏุฑ ุจุฑุงุจุฑ ุฎุทุง (Fault Tolerance) ุฑุง ุจู ุดุฏุช ุงูุฒุงุด ูโุฏูุฏ.
ุซุจุช ููุงุน (Logging) ุฌุงูุน: ุชูุงู ุนููุงุชโูุง ฺฉูุฏุ ุงุฒ ุฌููู ุจุงุฑฺฏุฐุงุฑ ูุฏูุ ุงุฌุฑุง ุงุณุชูุชุงุฌุ ุฎุทุงูุง ู ูุงูโุจฺฉโูุงุ ุจุง ุฌุฒุฆุงุช ฺฉุงูู ุซุจุช ูโุดููุฏ. ุงู ุงุทูุงุนุงุช ุจุฑุง ูุงูุชูุฑูฺฏุ ุนุจโุงุจ ู ุชุฌุฒู ู ุชุญูู ุนููฺฉุฑุฏ ุจุณุงุฑ ุงุฑุฒุดููุฏ ูุณุชูุฏ.
ูพุงฺฉุณุงุฒ ุญุงูุธู (Memory Cleanup): ูุฑฺฉุฑ ุจู ุทูุฑ ุฏูุฑูโุง ุญุงูุธู ุฑุง ูพุงฺฉุณุงุฒ ูโฺฉูุฏ ุชุง ุงุฒ ุงูุจุงุดุชฺฏ ุฏุงุฏูโูุง ุบุฑุถุฑูุฑ ู ูุดฺฉูุงุช ูุฑุจูุท ุจู ุญุงูุธู ุฌููฺฏุฑ ุดูุฏุ ฺฉู ุจุฑุง ฺฉุงุฑูุง ุทููุงูโูุฏุช ุญุงุช ุงุณุช.
ุขูุงุฑ ุนููฺฉุฑุฏ: ุงู ฺฉูุงุณ ุขูุงุฑูุง ุฏูู ุงุฒ ุฌููู ุชุนุฏุงุฏ jobโูุง ูููู/ูุงููููุ ุฒูุงูโูุง ุจุงุฑฺฏุฐุงุฑ ู ุงุฌุฑุงุ ู ุชุนุฏุงุฏ ุฏูุนุงุช ูุงูโุจฺฉ ุจู CPU ุฑุง ูฺฏูุฏุงุฑ ูโฺฉูุฏ ฺฉู ุจุฑุง ุจุฑุฑุณ ฺฉุงุฑุง ู ุจูููโุณุงุฒ ุณุณุชู ููุฏ ุงุณุช.

